All terms and points are covered here in a way I understood it.
***( - get to know the definition more
 
https://linkmeup.gitbook.io/sdsm/0.-planirovanie

White papers:
https://www.reddit.com/r/ccnp/comments/kpeefz/cisco_white_papers_i_used/

Anki cards:
https://ankiweb.net/shared/info/1981245053

#                    Network Design
Tier 2 network - Access and Distribution layer
Tier 3 network - Access, Distribution and Core layer
Collapsed topology - can be collapsed in following ways:
    Core-Distribution (2 modules), Distribution-Access (2 modules), Core-Distribution-Access (1 module)

L2 Access layer:
    STP have to be considered - links will be blocked (solution - PVST+ or assigning certain VLANs to certain links with no loops)
L3 Access layer:
    Costs more money but STP and Loops are not an issue anymore. Also can't easily stretch the VLAN

Modern techs to get rid of STP:
    Chassis switches (prevents loops, and no single point of failure)
    Stacking (prevents loops, and no single point of failure)

Access layer - devices, L2 switches
    Port security - MACs, 802.1x;
    QoS;
    VLAN tagging.
Distribution layer - SVIs, East-West traffic, sometimes L3 interfaces
    SVIs;
    FHRPs;
    ACLs;
    Routing protocols.
Core layer - high-speed, high-convergence, high-throughput, access to Internet
    RPs;
    fast l3 switching

DC new cool topology:
    Spine-Leaf

#                    High availability (HA)
FHRP (VRRP, HSRP, GLBP):
VRRP - virtual gateway protocol. 2+ gateways. Can't load balance. Common on all devices.
    "Master" and "Backup" routers
    VRRP exchanges hello messages over the timers (defaults are 3sec for HELLO, 10sec for HOLD)
    Can use one of physical router IPs as virtual. In that case, the router with that IP is an Active by default.
    VRRP authentication is recommended (MD5)
    VRRP priority (1-254). 100 is default. The bigger the better.
    After Master router switchover, "preemt" is required to be switched back over to previous active one. Preemt feature is *enabled by default
    VRRPv2 and VRRPv3 (used for IPv6) exist.
    VMAC = 0000.5e00.01** (256 different ones)
    MulticastIP = 224.0.0.18
    VRRP on Nexus with VPC (in DC) acts same as HSRP

HSRP - Cisco proprietary VRRP implementation. 2+ gateways
    "Active" and "Standby" routers. "Listen" as well
    HSRP exchanges hello messages over the timers (defaults are 3sec for HELLO, 10sec for HOLD)
    HSRP authentication is recommended (MD5)
    HSRP priority (0-255). 100 is default. The bigger the better.
    Preempt feature is *disabled by default
    Each HSRP process requires an HSRP group
    HSRPv1: 
        256 HSRP groups; 
        VMAC = 0000.0c07.ac** (256 different ones);
        MulticastIP = 224.0.0.2
    HSRPv2:
        4096 HSRP groups;
        VMAC = 0000.0c9f.f*** (4096 different ones);
        MulticastIP = 224.0.0.102;
        Millisecond timers are configurable.
    HSRP on Nexus with VPC acts differently. Usually all the traffic goes to Active switch and in VPC scenario it'll have to go through standby sometimes. That's why in given scenario, Standby switch handles the packets just like active. But it's still standby if checked hsrp status on switches. But some requests (like ARP) will still go to Active and be responded from it.
    It's a good idea to LB using HSRP by making one router primary for one VLAN and other router primary for other VLAN.
    
After switches get assigned a virtual IP, also they receive a virtual MAC-address. After first ARP from client, primary switch responces to packet. Whenever it's down and there appears a new primary switch which takes over the virtual IP (virtual MAC as well), it sends a Gratuitous ARP to say "now i have that MAC"
GARP - An ARP response when there were to ARP request.
FHRP object tracking helps to change the VIP holder to another device in case of some event. Following can be tracked:
    Route availability;
    Line protocol of an interface;
    Prefix reachability;
    IP SLA.

GLBP - Load balancing mechanism (Cisco proprietary). Similar to HSRP, but supports no less than 4 gateways
    "Active Virtual Gateway" (AVG) and "Active Virtual Forwarder" (AVF) states of router
    Traffic from connected endpoints is being sent to one of AVFs (AVG is also an AVF) and by that, gets load-balanced
    AVG is choosed based on priority
    Can be load-balanced based on:
        Round-robin
        Weighted
        Host-dependent (based on which host is sending the traffic)
    Timers and authentication are present as well
    VMAC = 0007.B40x.xxyy (x.xx is a Group ID, limited by 1024 different ones, since first "x" is 4 bits; yy is an AVF identifier which is "01-04", can be checkes by show glbp commands)
    MulticastIP = 224.0.0.102 (like HSRPv2)
    
SSO - mechanism that allows second CPU to take over the traffic and processing from other CPU in case of it's failure
    Can be used if device has two Route processes (control planes) and one is going down
NSF - Nonstop Forwarding. Allows data plane to send out packets to a neighbor even if it goes down control plane - wise.
    NSF feature must be configured on both devices to be operable
    Routes are being marked as Stale and will be exchanged once again when CP (control plane) goes up
VSS - stacking mechanism that allows two physical switches to be represented as a single virtual switch. Devices can be located in remote locations


#                    WLAN (wireless LAN) design
Comparison of basic Access devices (switches) to Autonomous access points:
    SVI (switched virtual interface)   ---    BVI (bridged virtual interface)
    VLAN                               ---    SSID

Autonomous design (old)
    Main issue for Autonomous deployment is low scalability. For Core deployments connected through L3, VLAN cannot be stretched reliably for clients to be able to move from one physical place to another and still be connected to same VLAN.
    Also it's difficult to configure a lot of device manually.
    Two devices below used to help configure a lot of devices. But there still were issues with pushing the config.
    WLSM (Wireless LAN Services Module) - EOS 
    WLSE (Wireless LAN Solution Engine) - EOS

Lightweight design (modern)
    WLC (Wireless LAN Controller)
    Access points are brainless and are used in conjunction with the controller (WLC). Once they're connected to network, they receive an IP through DHCP, retrieve Sotware image and configuration.
    Clients are connected to APs. APs establish a data tunnel (CAPwAP - Control and Provisioning of Wireless Access Points) so clients are connected directly to WLC from L2 perspective. Both Data plane and Control plane traffic are going through the tunnel.

WLC deployment design models
    Centralized (APs are in campus, WLC is in DC, tunnel is used to exchange traffic between APs and WLC).
        Pros: L2 Roam - VLANs are located on all APs, users can safely move from anywhere to anywhere and still be on their same subnet.
        Cons: Logically clients are located in the DC which is not quite secure. Also licensing should be considered. WLC controllers can manage only certain number of devices
    Distributed (Same as Centralized, but there are different WLCs for every building).
        Pros: Still L2 Roam within the building
        Cons: Licensing (1 WLC for certain number of APs) and number of controllers is increased.
    Branch (Flex connect) - used for small buildings. APs and WLC are deployed as in Centralised model but tunnel established between them only transfers Control Plane traffic. Data plane remains at AP and is sent out directly to Switch.
        Requirements: <100ms latency to WLC, <50 APs
        Pros: Efficient traffic route (no need to send traffic to DC first). Simpler WLC topology.
        Cons: No more L2 roam, but since it's a branch design it might not be needed.
    Cloud (Meraki) - Wireless controllers are located in the cloud. APs are installed on site and they transfer control plane traffic to the cloud. DP is going to upstream swtiches.
        Requirements: Cisco Meraki APs
        Pros: No licensing issues (increased with the number of used APs), no need to manage controller Hardware. Data traffic of wireless clients is passed to local switch instead of being tunneled to controller
        Cons: No L2 roam in case the Distribution switches (or access switches) are L3 interconnected 

Wireless AP deployment and placement
    COVERAGE
        Coverage is about wireless signal being available at every part of the office/campus/building with (preferrably) the same good strength. It can overlap between different APs and it actually is a standard. 35% overlap (for voice and video networks) and 20% overlap (for no video/voice) is desirable.
        When checking the signal of certain AP, end of coverage should be considered at the point where strength gets changed from -67 dBm to -68 dBm.
        Wireless CHANNELS should also be considered. There are 2 common ones: 2.4 GHz and 5 GHz.
        APs can have different antennas. Ones that give a signal to 360 degrees and ones that direct the signal in some angle (10-60 degrees)
        Cisco models can be with internal antennas (AP-I) or external (AP-E). External models antennas can be changed.
    CAPACITY
        Capacity is about number of clients per AP. 
        When preparing Wireless design, it should be considered how many people will use the AP to understand how many APs you need 

Cisco Prime Infrastructure - network management software platform. It provides a centralized management solution. The software allows administrators to monitor, configure, and troubleshoot network devices from a single interface, and can also be used for network performance analysis and reporting.

Real Time Location Services (RTLS) - service that helps to understand where does the certain device is physically located in the building (it have to be using WIFI at the moment)
    Can be used with RFID tags to check the location of anything (wheelchair in hospital for example)
    Also if it leaves certain area, there can be an alert
    
    Data is collected by WLC and APs but a separate Software is required to gather and analyze the data
        CPI
        CMX
        DNA Center (SDA)
        DNA Spaces (SDA)

    Accuracy. 
        Basic: We can always tell which AP is device connected to.
        Advanced: Triangulation. Assume there are 3 APs. A wireless device is in a reach of every AP (ex. -42 dBm, -59 dBm, -63 dBm). Every dBm level can be drawn as a circle around each AP. When 3 circles are drawn, there's just a single point where all of them interconnect. Like that location can be determined. But only in a free space without any walls.
                  ***(have to clarify, too tired to write it down correctly) RF Fingerprinting. Technic of profiling the wireless coverage. Just walk around with wireless device around the block for APs to understand how it all look like logically.


#                    Cloud computing solutions
Identification of Cloud.
According to NIST (National Institute of Standards and Technology), some system can be identified as a Cloud computing solution (example is Public Cloud like AWS, Microsoft Azure, Google Cloud Platform) if:
    1. It supports self-service - Customer can log in to account and just spin up a new VM or service.
    2. It has a broad network access - It is highly available from as much regions of the world as possible.
    3. It supports resource pooling - Anyones VM in cloud can be running with few other VMs from other companies. Multitenancy is used for companies to be secured from each other.
    4.* It supports Rapid Elasticity - Resources for clients VMs can be smartly (by itself) expanded whenever the demand is higher than usual and shrinked back to normal when demand falls off.
    5.* Services are Metered - All the usage of resources is being counted just like electricity in houses. Customers pay for all their usage monthly (usually monthly but there can be exceptions).

Cloud models
    No cloud:
        In no cloud environment (basic DataCenter), your systems engineers are responsible for spinning up a VM, installing an OS on it, and an Application usually.
        It can look like below:
        _______    _______    _______
        |  ___ |   |  ___ |   |  __  |
        | |APP||   | |WEB||   | |DB| |
        |  ‾‾‾ |   |  ‾‾‾ |   |  ‾‾  |
        |  __  |   |  __  |   |  __  |
        | |OS| |   | |OS| |   | |OS| |
        |  ‾‾  |   |  ‾‾  |   |  ‾‾  |
        |___VM1|   |___VM2|   |___VM3|
       
        3 VMs, one with OS and Application, another with OS and WEB-server, third one is with OS and DB. All deployed and supported by your company
        (VM, OS, APP, WEB, DB)
    
    IAAS (Infrastructure as a service). Cost $
        VMs are deployed by Cloud provider. You only control which OS is being installed and what services are there
        (OS, APP, WEB, DB)
    
    PAAS (Platform as a service). Cost $$
        VMs and OS are deployed by Cloud provider. You only control applications, WEB-server and DB
        (APP, WEB, DB)
    
    SAAS (Software as a service). Cost $$$
        VMs, OS, WEB-server, DB are deployed by Cloud provider. You only control your Application and support it.
        (APP)
    
Cloud Deployment Models
    Public - all the companies resources are on the cloud. Highly available, but data is stored on remote servers and VMs are on same hardware with other companies.    
    Private - all the companies resources are on the cloud resources dedicated specifically for this company. 
    Hybrid - a combination of both Public and Private cloud. Some apps might be published to public, some to hybrid, it can depend on the sensitivity of stored data.
    Community - a cloud environment created by two or more organizations for access for all of parties to a single common cloud of services

Pros of certain models:
    Private: 
        Security (you can restrict access to the resources);
        Data sovereignity (you own the data therefore it's yours only);
        Lower cost when a lot of users.
    Public:
        Elasticity (you can grow the amount of resources whenever needed or shrink them);
        Services (you can get some services that can't be obtained in Private model, like serverless computing);
        Simplicity (just run servers and use).
    Hybrid:
        All pros of above models are included

In Hybrid model, Cloud brokering is involved.
Users (when spinning up an application) are going to cloud broker, Like Cisco Cloud Center. And then they can choose where to deploy their APP:
    Private cloud;
    Public cloud (AWS);
    Public cloud (Azure);
    Public cloud (GCP).


#                    SD-WAN
SDN (Software-Defined Network) - network that is managed in a centralized way (though a controller or using scripts)
Additionally SDN have an underlay and an overlay. And usually tunnels is used to make sure overlay works as intended
SD-WAN  is an SDN applied to devices related to WAN (edge router for example)

SD-WAN  is separated into 4 planes (Orchestration, Management, Control and Data)
In usual network, Control and Data plane are both living on same device.
In case of SD-WAN (and SDN), controller is responsible for Control Plane (brain of network). Edge devices are responsible for Data plane (legs of network).

Differences:
WAN                                                             |   SD-WAN
________________________________________________________________|__________________________________________________________________________
Each device has own control plane                               |   Centralized control plane
All configuration, upgrades and monitoring done on each box     |   Configuration, upgrades and monitoring done centralized
Automation only through scripts                                 |   Automation can be done using API or scripts
New installation done from scratch                              |   New installation can be done with help of ZTP (Zero-Touch Provisioning)

Cisco solution was initially iWAN (intelligent WAN) but that failed and they made a purchase of Viptela company.
Currect solution is "Cisco SD-WAN". Also they have a Meraki SD-WAN solution

Cisco SD-WAN components:
    vManage - User logs in to it and configures all the settings required to be run on devices. Centralized management and monitoring happens here. Can be configured using REST API.
        DEMO: https://sandbox-sdwan-2.cisco.com/ (devnetuser/RG!_Yw919_83)
        Templates are used to push the predefined configuration to devices.
    vSmart - A controller, CAN ONLY BE VIRTUAL (public/private cloud or on-prem). It sends out the configuration (that has been configured on vManage) to routers. Config like Security/QoS/VPNs
    vEdge - Basically a Router. It is interconnected with other routers via IPsec tunnel. So underlay is a Provider network. Overlay is tunnels
        vEdge can be deployed in a Cloud therefore be virtual.
        Also there's a cEdge - Cisco ISRs with Viptela code running on them. Used to be able to support T1, E1 (Voice, serial) lines, or some security features
        Represented by Cisco devices (ASR 1k, ISR 1k, ISR 4k, ENCS 5400), device runs IOS-XE 18.3.0+
        It is not recommended to run both vEdges and cEdges in the same location
    vBond - An orchestrator (virtual deployment only, it must have a public IP) with OOB view on the SD-WAN. Used to glue all the components together. Orchestrates the connectivity between vEdges and vSmart controller.
        Whenever new vEdge device join SD-WAN, it goes to vBond which sends out the info to vManage. Then Administrator can approve or reject adding the vEdge to SD-WAN
        Can help for two vEdges to build an IPsec tunnel if both of them are behind NAT - that is called NAT traversal
        Example: it sends out a packet to two vEdges which open the certain ports. Devices then use that ports to build a tunnel. Or it can orchestrate so those devices exchange packets themselves.
                
Cisco SD-WAN topologies:
    Full mesh (requires license)
    Partial mesh (requires license)
    Point-to-Point (kind of requires license)
    Hub-and-Spoke (no license required)
    
    There are 4 different options in which SD-WAN solution can work whenever there are more than 1 WAN circuit (WAN or INTERNET):
        Active-Active (traffic is fairly splitted between two circuits)
        Active-Active weighted (traffic is splitted between two links but amount sent through each depends on the bandwidth) 
        Active-Standby (traffic is sent through Active only and is being failovered in case of issues on Active)
        Application-aware SLA - used to be able to see circuit degradation even if it's still up. Used to track the availability of some metrics for the circuit. DPI (required additional license) can help to identify the application.

SD-WAN Programmability
    NETCONF - a protocol that allows to send a configuration (XML) to devices using SSH
    REST APIs - a protocol that allows HTTP/HTTPS requests (GET, POST, DELETE, PUT) to be sent to some device. That allows to receive status and configuration of system

vManage GUI is actually a set of REST API replies received by sending the requests through the web page.
vSmart receives configuration changes from vManage by NETCONF
vEdges receive configuration from vSmart through OMP (Overlay Management Protocol)

Controller deployment models
    Public model: all components are deployed (and MANAGED!) by Cisco in their AWS space (2x vSmarts active/active; 2x vBonds Active/Active; 2x vManage Active/Standby). All of them have to be reachable through public internet space
    Hybrid model: controllers are now deployed in company's public cloud, or in the DC. VMs are Managed by the companies engineers. Their public IPs have to be reachable through all WAN circuits.
    Hybrid model w/private IPs: same as hybrid models but private IPs are used. In that case NATting is required since vBond have to have a PUBLIC IP-address.

Cisco SD-WAN hardware
    vEdge-100b (100Mbit connectivity max, both download&upload, ethernet only)
    vEdge-100m (100 but supports 2G/3G/4G modem)
    vEdge-100wm (100 but mobile + wireless)
    vEdge-1000 (1Gig connectivity throughput)
    vEdge-2000 (10Gig connectivity throughput)
    vEdge-5000 (20Gig connectivity throughput)


#                    SD-Access
SDN applied to Access layer of network.
All border devices in SDA have a VXLAN tunnel to every other device.

Traditional challenges:
    STP
    Manual config
    Poor scalability
    Difficult security policy

SD-Access is Campus Fabric with DNA center as a controller for the network.

Campus Fabric is:
    VXLAN used to build tunnels as overlay mechanism
    Location Identifier Separation Protocol
    CTS (ISE basically) - Cisco TrustSec

DNA Center is a physical appliance only(!)


SDA doesn't operate in subnets. If a new EP comes online, nobody knows a destination to it at first.

Cisco SD-Access layers:
    Physical (equipment)
        Control plane node (LISP) - a device responsible for storing the data of mappings (mappings DB) of each device (hosts, switches) in the network to other devices
        Fabric border device - Core
        Fabric intermediate device - Distribution
        Fabric edge device - Access
        Fabric WLC
    Network (logic and physics of the network)
        VXLAN - Data plane. Builds direct tunnels but don't have information of where to direct traffic to.
            (!)Additional 50 Bytes are used for the encapsulation. MTU of underlay should be increased by that number
            Usual Packet: [eth|IP|data]
            VXLAN Packet: [eth|IP|VNID|above_packet_as_data]
            VXLAN-GPO is introduced by Cisco to serve it's purpose on the Policy plane. It includes SGTs (Scalable group tag) to manage the policies received by hosts
        LISP (SDA) - Control plane. Directs the traffic to required switch or node of network.
            Each network device (switch or router) has an RLOC (Router LOCation) which identifies it in a network (usually it is a LOOPBACK address). 
            Each endpoint has a EID (Endpoint ID) and is bound to current RLOC (EID-RLOC mapping on CPN)
            Whenever traffic has to be sent from an endpoint to another enpoint, switch requests the direction from Mapping server (control plane node) and then just directs traffic as necessary
        CTS (cisco trustsec) - Policy plane. Used to enforce existing policies to ongoing traffic.
            Microsegmentation (two hosts on same network shouln't talk to each other). SGs (scalable groups) used for that.
            Macrosegmentation (two hosts on same switch, diffrent network shoulnd not have any possibility to access each other. VNs (virtual networks) are used for that. Each host is in it's own VN.
            Whenever traffic is received by network device, it receives a VN (virtual network) and SG (scalable group) tags. These are transformed into VNID and SGT afterwards to be trasfered further into network. By receiving device, policy is being applied according to tags.
            Tagging happes on ingress traffic and policy enforcement happens on egress traffic.
    Controller (a controller of whole solution + ISE)
        Cisco DNA center
            Network control platform
                Configures network devices automatically for us
                APIC-EM
                Automation engine (underlay & overlay), CLI/SNMP, NETCONF/YANG
            Network data platform
                Analytics engine -> Data itself. DNA collects all possible data (SNMP, Netflow, Syslog, Streaming Telemetry(retrieve preset bunches of data)) and writed to DB
                Assurance engine -> Value from data. Proactive monitoring (problem is boiling up), visibility (healthscore), configuration suggestions (can be run using autimation engine), path trace
    Management (GUI, REST APIs, CLI)
        4-step workflow
            1. Design (conf settings, profiles, definitions)
            2. Policy (set policy (ISE, AAA and stuff))
            3. Provision (assign role to a device)
            4. Assurance (monitoring of health of network)

ISE is a security solution used in SDA. It provides:
    Visibility (who, when, how, where connects)
    Segmentation (microsegmentation using SGTs - security group tags)
    Stop Threats
    
    Can be integrated with 3rd party solutions (Cisco ACI or other vendors) using pxGrid.

User Authentication process in SDA
    For 802.1x to happen, there have to be a supplicant - some piece of software for 802.1x exchange to happen from the endpoint.
    -- Supplicant (PC) sends a login request (802.1x exchange) to Network Authentication Device (NAD), usually an upstream switch.
    NAD forwards the request using RADIUS to ISE 
    -- Endpoint (Phone) is being authenticated using MAB (MAC Authentication Bypass). Whenever phone is connected to network, NAD expects 802.1x exchange.
    Since it's a phone, it doesn't happen therefore MAB exchange with ISE happens. For that MAC-DB is required and manual adding of every MAC to ISE is required.
    -- WebAuth also exist. An endpoint doesn't have any 802.1x supplicant installed.
    Endpoint connected to network gets a DHCP address with DNS servers. After that when enpoint tries to access a website, request gets intercepted and EP is directed to ISE to login.

SDA EP onboarding
    EID in SDA is the IP-address of Endpoint connected to fabric.
    Whenever device is connected to network, it get's tagged with EID and switch A send out a registration message to control plane node (CPN).
    After that CPN know about that node and whenever some other switch (B,C) wants to send traffic to that EID, it forwards it to required switch A.
    If switch B or C already sent traffic to that EID, info about direction is stored in their DB so they know the RLOC to which they should send that traffic further on (expired if no data is sent in 24H)
    In wireless, another VXLAN tunnel is formed with AP and it's data traffic is sent through that tunnel instead of CAPwAP tunnel (as usual)
Client ROAM
    If client roams (moves frow Switch A to Switch B):
        1. Switch B send info to CPN about client being on it
        2. CPN informs Switch A about client not being on A anymore
        3. If some other switch send a packet to Switch A thinking client is there (saved in cache for example), Switch A responds with "no it's not here" and ALSO send packet to Switch B
           Other switch then updates it's DB from CPN and now stores new cache

External subnets in SDA
    Internal border node - connects with internal subnets (DC, legacy, other) 
    External border node - connects with external subnets (Internet)
    When fabric devices send traffic to other subnets, process is similar, they ask CPN and it forwards traffic to certain border node.
    After that, border node sends out traffic according to basic Routing protocols.

SDN implementation and effect upon planes:
Imperative approach - Only controller has control plane. In case devices loose connectivity to controller - they're dead since no decision can be made
Declarative approach - Devices has their own control plane which replicate the state from controller. In case connectivity to controller is lost, devices can handle traffic on their own

ETA (encrypted traffic analytics) - technical suite allowing to check encrypted traffic for malware without decrypting it
Includes:
    Stealthwatch
    ISE
    Cat 9K
    
    Data is collected by Stealthwatch and forwarded to Cognitive Intelligence - Cisco Cloud system that scans the traffic in 3 steps:
        1. Anomaly detection. Is traffic Malicious or Weird?
        2. Malicious events. What is it, what it has done?
        3. Threat Analysis.
        Then the score (1-10, 10 being the most malicious) is set for traffic.


#                    Hardware

9k Switches
    Good thing about 9k switches is that they support UADP (Unified Access DataPlane ASIC technology) - features can be added to it through patches.
    9200 (stack, UADP-Mini) - used to replace Catalyst 2k
    9300 (stack, Modular) - used to replace Catalyst 3k
    9400 (chassis, SwV(VSS)) - used to replace Catalyst 4k 
    9500 (fixed) - used to replace 4500X, 6880-X (CORE) 
    9600 (chassis, SwV) - used to replace Catalyst 6k (CORE)

Routers
    ISR (4300, 4400 supported by SDA) - focuses on features, not on performance. UCS and other stuff can be deployed on it
    ASR (1000 supported by SDA) - focuses on performance, bandwidth, table sizes (BGP internet table for example)
    
Wireless
    WLC (Catalyst 9800s) - a 9k Cisco that serves as a WLC
        HW (9880, 9840, 9800-L similar to 9200-L, 9300-L)
        SW (Embedded WLC, 9800-CL (CL for cloud)). Cloud version can be deployed in private DC or in Cloud
    APs (9100) - supports mGig technology which allows transfer of big Gbit/s (up to 10) through WIFI.


#                    QoS (Quality of service)
QoS - allows the manipulation of traffic (packets) in a way to prioritize some important data to be transfered with better confidions (sometimes be transferred at all - in case bandwidth of an interface is lower that the amount of traffic)

Mechanics:
1. Traffic is classified
    3 bit number in a frame (in 802.1Q field) that immediately tells Network Device (like a mark on an Amazon package) what is that traffic
2. Traffic is marked
    8 bit ToS field in a packet. Before IPP (IP Precedense) was used with 3 bit. Now it's DSCP (Differentiated services code point) with 6 bit
(*)1 and 2 doesn't do anything by itself, these are just numbers in traffic. If device doesn't have any rules about how to handle such traffic - they're useless
3. Traffic is threated based on 1 and 2

QoS tools:
1. Classification & Marking  sa- used for ingress traffic. Packets get classified (by source, destination IP, protocol, ports) and marked on ingress interface with certain priority for egress interface to understand how it should be forwarded. 
    NBAR (Network-Based Application Recognition) exists which lets the classification to happen with more details (based on word, phrase or URL for example)
2. Policing - used on ingress interface (provide edge interface facing customer edge device) to drop all the traffic that exceeds the configured policing bandwidth. Can be configured for different types of traffic (TCP, UDP, DNS, other apps.)
3. Shaping - used on egress interface to create queues (queueing) which allows traffic that exceeds the configured bandwidth to be sent later, whenever the circuit is less busy. 
4. Queueing - used on egress interface to divide egress queue on sub-queues
5. Scheduling - used to empty the sub-queues in a certain way.

Marking:
On layer 1: based on physical port or interface (subinterface/SVI)
On layer 2: based on MAC-address and on COS (class of service) bits (802.1P)
On layer 3: based on IP-address (source/dest) and on DSCP mark (TOS bits)
On layer 4: based on TCP or UDP port
On layer 7: using NBAR2 - determine the application based on signatures that are stored on cisco devices

Congestion management - a set of tools (egress interface) that manages happened congestion. WFQ, CBWFQ, PQ, LLQ, WRR, SRR, Shaping.
    Weighted Fair - low-bandwidth traffic is done first. Problem: important traffic can be stopped from transmitting
    Class-based - guarantees a service to get a definite amount of bandwidth (40Mbit/s out of 150Mbit/s link). Can't guarantee the priority
    Priority - Guarantees the priority queue over other traffic
    LLQ (low latency queuing)
Congestion avoidance - a set of tools (ingress interface) that prevents congestions from happening. RED, WRED, WTD, Policing.

QoS models:
Best Effort - usual device behaviour. Packets being sent if possible. If there's congestion, packets are queued and are sent on FIFO basis. They are taildropped if buffer is overflown.
Integrated services - unified settings on all the routers on the way. Uses RSVP (Resource Reservation Protocol). A certain bandwidth is reserved by RSVP packet that is being sent before the call establishment. If there's no bandwidth available - call is dropped.
Differentiated services - each router has it's own settings. Uses PHB (Per-Hop Behaviour). DSCP marking happens here that can assure traffic to be passed further.

QoS Policies
Before all QoS settings had to be applied to interfaces.
Now QoS settings are applied globally. Interfaces are used to display the direction of traffic for QoS to be applied.

MQS (Modular QoS Command-Line):
QoS applied globally.
Allows for different QoS tools to be applied to different interfaces.
3 components:
  Class-map - used to match certain type of traffic and classify it
  Policy-map - used to match certain traffic classified by class-maps. To initiate the use of class-maps
  Service-policy - used to apply a policy-map to interface. Inbound/Outbound.

QoS Marking rules:
Layer 2
    CoS (Class of Service) - 3 bit number in a frame (in 802.1Q field). Can take numeric values from 0 to 7
Layer 3
    ToS (Type of Service) - 8 bit field (names ToS) in a packet (L3). It is categorized as per below:
        IPP (IP precedence) - takes 3 bit in ToS field -> as CoS, values can be from 0 to 7.
            Best practices (not mandatory) are:
                value 0 for FIFO traffic
                value 1-4 for priority traffic (1 being scavenger traffic which is some junk from users like bittorrent and others)
                value 5 for VoIP
                value 6-7 for network traffic (STP, routing etc.)
        DSCP - takes 6 bit in ToS field -> divided in "major" and "minor" bit groups of 3. That is for intercompatibility of two methods of marking.
            Major bits are same as used by IPP - "Class Selector"
            Minor bit group is called "Drop preference"
            DSCP is split as: AF (Assured forwarding) with a two numbers - first being it's class (higher is better) and second is a drop preference (lesser is better).
                              CS (Class selecter) is just a usage of first 3 bits which is a class. Drop preference is 0 - not used.
                              EF (Expedited Forwarding) - usually used for Voice. Class 5 and Drop preference value is higher (11)

Very useful "QoS Values Calculator":
https://i.pinimg.com/originals/34/a7/57/34a75767cda2db32f3aca013b65d91af.jpg

1. Traffic from 10.0.0.1 to 10.255.1.1 is matched and classified by class-map.
2. Policy-map initiates the class-map and makes the classified traffic to follow the specified rules. Apply policing for all the traffic from 10.0.0.1 to 10.255.1.1 (from gi0/1 to gi0/3) to prevent it from congesting the interface gi0/1.
3. Apply service-policy to interface gi0/1 (inbound) and interface gi0/3 (outbout) to use the above rules for this traffic.

It is a best practice to move "Trust boundary" as close to Endpoints as possible (wherever this can be safely applied, like IP phones).
Trust boundary is the point where marking can happen - it loads up resources.



#                    Network device architecture
Process Switching - old intra-device frame/packet switching mechanism. Every frame/packet received by device is forwarded to CPU for it to lookup the MAC / Routing table and decide where Data unit should be egressed.
Fast Switching - attempt to remove CPU from the process as much as possible. Cache is introduced. Destination is stored in Cache after single packet has been "process switched"
    can be enabled by command on interface "ip route-cache". Fast Switching happens REACTIVELY

RIB - a "Database" of all the information about learned routes on the device. Routing Table includes a formatted data taken from RIB.
    RIB entry contain: "Letter of used routing protocol" - "AD" - "METRIC" - "IP-address" - "Subnet Mask" - "Next-hop IP" - "outbound interface"
CEF (Cisco Express Forwarding) - Cisco proprietary mechanism for DataUnit switching. It allows for switching decisions to be made PROACTIVELY.
    Before packet with unknown destination arrived, a FIB table is populated from the RIB. FIB table contain Network, Egress interface and Next-hop address (MAC)
    In recent CEF implementations, all the FIB data is collected beforehand from RIB.

FIB - a copy of RIB (network+egress interface+nexthop) + ARP lookup for destination(nexthop) MAC-address. Used for switching decisions in CEF.
Adjacency table - an L2 information with MAC-addresses for packet to be reincapsulated into a new frame (with new source and destination MACs) while forwarding.

https://linkmeup.ru/podcasts/959/ --- CEF, Process Switching deep dive

Below are used for quick lookup by network device. Lookup on MAC-address / Routing, ACL, QoS.
CAM - located in a RAM (high-speed memory for quick lookup). Contains the information about MAC addresses of devices in subnets. MACs are represented as MAC-address table. Can only be used by switches
    Can only be looked up by the exact match for MAC-address
TCAM - located in RAM (high-speed memory for quick lookup). Contains IP-addresses and subnet masks. Also contain ACL/QoS rules. Provides as assistance with decision of best path based on longest match (/30 mask is longer match than /24). Subnets and masks are represented as Routing table. Can be used by routers and multilayer switches.
    A request to TCAM is made by providing IP address and Mask and getting a result (next hop IP, permit/deny responce) in answer.
    Lookup is made in following format: V,M,R (V-Value(IP),M-Mask,R-Result(allow/deny,nexthop))
    TCAM is ternary - there is a possibility to specify that something is 0, 1 or X (whatever). That allows for Mask to be stored (for example 27 mask would be 11111111.11111111.11111111.111XXXXX)
***(get to know more on CAM & TCAM)
RP (route processor)

Centralized and Distributed switching architectures
Centralized - Packets that has been received by interface on Line card are forwarded to Supervisor before switching decision (CAM & FIB lookup)
Distributed - Packet received on Line Card is forwarded firectly out of line card through corresponding interface (CAM & FIB tables are stored on LC but populated by Supervisor). Control traffic (like OSPF) still happens on Supervisor


#                    Virtualization
#        ENDPOINT VIRTUALIZATION 
Hypervisor - a utility that allows management and provides visibility of Guest OSes (VMs)

Hardware server is called "HOST"
Virtual server is called "GUEST"

Type 1 hypervisor - a hypervisor that is installed directly on Hardware (HW --- Hypervisor --- VMs)
Type 2 hypervisor - a hypervisor that is installed on some OS like Microsoft Windows (HW --- OS --- Hypervisor --- VMS)

Usually Type 1 HV is used in Production networks (in DC), Type 2 is used for LABs and not recommended for PROD deployments.
VMs basically is a data, it's all files that are used and manipulated by Hypervisors. That allows to store them on external "Storage arrays". Which allows VMs to be access not just by a single HV but by many others.
So if some HOST goes down, another HOST can overtake the VM and spin it up on itself
Also VMs can be moved between HOSTS (VM migration)
    Cold migration - VM is turned down and spin up on another HOST. Both HOSTs should be able to access storage with VM files
    Live migration - VM is migrated withoup being turned off. It can be configured to happen automatically if some HOST gets clogged with VM resource utilization
    
Additionaly there's a feature called FT (Fault Tolerance) which is basically the HA.
    If there's a VM on a HOST 1, a copy of it is run on HOST 2 which has FT configured with HOST 1. If HOST 1 is down, VM is getting up on HOST 2 with little to no downtime.

Virtual Switch (vSwitch) - literally a virtual switch inside HOST that connects it's virtual interfaces (ports) to VNICs distributed to running VMs. 
vSwitch can distiribute certain connected devices to their own broadcast domains ("VLANs"), this function is represented by port-groups.
Virtual Switches exist on type1 Hypervisors by default (ESXi vSwitch, Microsoft Hyper-V)
Broadcasts received by vSwitch are forwarded only to VMs living on the vSwitch. 
Supported features: VLANs, CDP, SPAN, Trunk
Traffic flow mechanism PINNING is used to prevent vSwitches from learning upstream MACs
Above is Standard deployment of vSwitch.

Also Distributed deployment exists:
    Allows for centralized deployment of vSwitches to many HOSTs and further management (and configuration management)

Cisco ENCS 5000.
    Allows for virtualization of network devices (CSR - CloudServicesRouter, ISRv, vWLC, ASAv, vEdge/cEdge)
Also can be virtualized on other server hardware.


#        DATA PATH VIRTUALIZATION
VRF - A technology that allows router (or Multilayer device) to logically be divided into few other routers (which basically means into few independent Routing tables)
    It is impossible to share routes between VRFs, one VRF can be reachable from another VRF only if there's a connection between them through external interface.
Each VRF will have their own routing table (for example that allows few similar (10.0.0.0/24) subnets to be defined in each VRF and still be reachable).
Usually used in ISP networks therefore requires ISP network technologies (MPLS, VPN, L3VPN, BGP).

***(VRF-Lite - an Enterprise solution that allows routing to be done through common routing protocols (OSPF, EIGRP). No extra VPN protocols required.

VRF Configuration:
    vrf definition <vrf_name>
    address-sapce
    *add interface to vrf forwarding (IP address get's stripped from interface here)

Tunnel - an overlay technology allowing for isolation of traffic from the underlay networks and providing direct L3 connectivity even between devices located far away from each other
GRE (Generic Routing Encapsulation) - a tunnelling protocol that allows an incapsulation of IP or other packets
    GRE encapsulation adds a GRE header (4Byte) and an IP header (20B).
    IP protocol number for GRE encapsulated packet is always 47 (https://en.wikipedia.org/wiki/List_of_IP_protocol_numbers)
GRE recursive routing: there might be an issue that the tunnel destination addressed is being routed through the tunnel itself.
To avoid that, tunnel and underlay networks should be in different Routing Domains (OSPF and EIGRP; EIGRP AS 1 and EIGRP AS 2; any other pairs except for the same ones)
!   MTU IS IMPORTANT. Tunnel default MTU is 1476

GRE configuration:
    interface tunnel<#>
    tunnel source
    tunnel destination
    ip address
    keepalive <interval> <retries_until_down> (keepalive is unidirectional - the packet that is originated on the router is destined to ITSELF; GRE header is added to packet, routed to tunnel destination, GRE header is stripped on the other side and uncovered IP packet is destined to the original router)

IPsec - a framework (set of tools) that allows a construction of secure tunnel from one destination to another
    Key features that IPsec provide are data...:
        AUTHENTICATION - packet exchange is happening between certain devices and they make sure it's actually them
        INTERGRITY - allows to make sure that data that contains in packets are the same on source and destination devices
        CONFIDENTIALITY - allows the encryption of the exchanged data

IPsec can have two different packet headers:
    AH (Authentication Header) - IP protocol 51. Allows to fullfill the data AUTHENTICATION and INTEGRITY. Can't encrypt
    ESP (Encapsulation Security Payload) - IP protocol 50. Can do all data features of IPsec. Also can do NAT traversal. 
        ESP can work in two modes:
            TRANSPORT Mode - When original IP packet with payload arrives to router, ESP header is added between Payload an previous IP headers. After that GRE header will add up in front(?)
            TUNNEL Mode - When original IP packet with payload arrives to router, ESP header is added in front of whole packet. another IP header is added in from of ESP header after that.

Both Transform sets have to match between devices.
Transform sets include Hashing algorithm of choice, encryption algorithm as well.
Transform sets are initially exchanged through IKE (Internet Key Exchange) tunnel.

Before establishing an IPsec tunnel between routers, they have to exchange the security settings that should be used (encryption keys as well etc.)
For that, IKE is used to build a Control plane tunnel (also called SA - security association).
IKE is an implementation os ISAKMP (Internet Security Association Key Management Protocol).
IKE:
    IKEv1. Consists of two phases of communication:
        Phase 1. Control plane tunnel is build with no encryption (def lifetime is 24hours, reestablished after). Following information is negotiated:
            Acronym to remember is HAGLE
            HASH 
            AUTHENTICATION METHOD
            GROUP (Diffie-Helman) - used to securely encrypt keys for encryption and decryption of traffic
            LIFETIME of a tunnel
            ENCRYPTION algorithm
       Phase 2. An IPsec tunnel (def lifetime is 12hours, reestablished after) itself can be established after phase 1 is completed 
            PFS - used to force use of different session keys other than ones that were used during phase 1.
    IKEv2. Phases are collapsed and less messages have to be exchanged before tunnels are established.
    Both devices have to use same IKE version.

IPsec configuration steps:
    0. Configure IKE phase 1.
        //crypto isakmp policy <security value> (lesser value - more prioritized)
         //hash <value>
         //authentication <value>
         //group <value>
         //lifetime <value>
         //encryption <value>
        *if auth - psk* //crypto isakmp key <KEYVALUE> address <IP_OF_TUNNEL_DESTINATION>
    1. Configure Transform-set (//crypto ipsec transform-set <TS_NAME> <PACKET_HEADER_VALUE>-<HASH_VALUE> *if ESP*<PACKET_HEADER_VALUE>-<ENCRYPTION_VALUE>)
        a. Choose AH or ESP
        b. Specify HASH and ENCRYPTION
        c. If ESP: Tunnel or Transport mode (//mode <tunnel-or-transport>)
    2. Configure IPsec Profile (prev. Crypto-map). Create a link to transform-set in IPsec profile. (//crypto ipsec profile <PROFILE_NAME> -> //set transform-set <TS_NAME>)
    3. Apply IPsec Profile to Tunnel interface.
        *under tunnel configuration* //tunnel mode ipsec ivp4
        //tunnel protection ipsec <PROFILE_NAME>

But before configuring IPsec, IKE (ISAKMP) have to be configured:
    crypto isakmp policy (HAGLE)
    (if PSK)crypto isakmp key <key_value> address <IP_address_destination>

Tshoot:
    show crypto isakmp sa
    show crypte ipsec sa

VPN types
    Site-To-Site - Basic tunnel between two sites. Tunnel can be established between Cisco and other 3rd party device. Lacks Routing, Multicast, Scalability.
    DMVPN - A hub-and-spoke VPN topology. Many sites establish VPN to the main site. With that it's not required to create a lot of tunnels. NHRP protocol is utilized. Routing is configurable. 
    FlexVPN - A "DMVPN+". It utilizes IKEv2 (can only use version 2 while other VPNs MAY use v1 OR v2) to make DMVPN better but is a different VPN solution
    GET VPN - a VPN for WAN over MPLS networks. Allows to keep the original IP header (with QoSes and other stuff).    


#                    LISP (as an independent protocol)
Was designed to help with the growing amount of routes on the edge Routers (940K+ routes at the moment of writing).
Instead of having all routers have all the prefixes existing in the internet, LISP allows to have a router domain where packet destined to certain IP, have to be transfered just to the router that has this IP-address on itself.
All the routers on the way form an Underlay network and doesn't have to know the location of end subnet because packet is encapsulated with additional LISP, UDP (4341) and IP headers. They forward packet to end router.
That removes the load of knowing all prefixes from many routers.

There are Control plane and Data plane available:
    Control Plane (LISP) - Where should the packet be forwarded. Mapping server helps to understand where should packet be forwarded.
                           Mapping Server has access to all the routers on "as-needed" basis as opposed to "have-all-prefixes-at-the-same-time" of usual Routers.
    Data Plane (LISP) - How should packet traverse the network to reach the destionation. 
                         Answer is - TUNNELING. Router that first receive the packet is ITR (Ingress tunneling router), last router that receive the packet - ETR (Egress tunneling router). These are relative so sometimes named xTR.
                         A usual IP packet in encapsulated on entering the tunnel.
                         LISP header is added to it with INSTANCE ID information (helpes to identify VRFs as VNID in VXLAN)
                         UDP header is added. UDP port that is used - 4341. Source port is dynamically that optimized Load Balancing in the environment ***(OPTIMIZE?)
                         IP header is added. With tunnel IP addresses for packet to be able to reach the destination (RLOC of remote router).
                         
LISP is used to separate Location and Identity.
In LIPS, each router has it's own Locator = RLOC. And each router has a subset of EIDs (endpoint IDs) which are usually subnets.

There are Map Resolver (MR) and Map Server (MS). Usually these are routers. And usually MR and MS are combined in one device.
Whenever new EID is added to RLOC, it is reported to Map Server. 
After that whenever other router has to send traffic to that new EID, Ingress router can send a request to MS and will then know where does subnet lives.

If there's a traffic going outside the LISP domain (external), edge router takes a role of a proxy. 
It can be either Proxy Egress tunnelling router (PETR) or Proxy Ingress tunnelling router (PITR), depending on the destination of traffic.

LISP operation:
Whenever Router gets connected to LISP domain, it shares it's EIDs (subnets) to the MS. That allows MS to know subnets connected to routers.
    1. Router 1 gets into LISP domain.
    2. It sends "MAP REGISTER" message to MS with subnet A in it.
    3. MS adds subnet A to it's table and send back the "MAP NOTIFY" message.

Whenever another router (router 2) wants to send a packet to subnet A on Router 1:
    1. Router 2 sens a "MAP REQUEST" message to MR.
    2. MR checks the table and sends "MAP REQUEST" further to Router 1 since the subnet is there.
    3. Router 1 then sends a "MAP REPLY" message back to Router 2.
    4. Then the LISP tunnel is getting formes to send traffic directly between routers. Packet's IP header includes source IP of Router 2 and Destination of Router 1. Real packet IPs are not known to devices on the way.

Whenever the packet is destined to some subnet that does not exist in the LISP domain (located externally):
    1. Router 2 sends out a  "MAP REQUEST" with subnet Z to MR.
    2. Since there's no subnet Z on MR, it replies with "NEGATIVE MAP REPLY" - subnet not found in DB message. That means that subnet must be outside on LISP domain.
    3. After that Router 2 sends out the packet to PxTR device to handle. 
        
PxTR does not add upstream subnets to the MR DB.


#                    VXLAN (as an independent protocol)
VXLAN allows L2 packets to be successfully traversed over the L3 network.

Usual Frames (with ETHERNET header included) are being encapsulated and following are being added to them:
    1. VXLAN header (8 Byte)
    2. UDP header (8 Byte)
    3. IP header (20 Byte)

    Above is called "MAC-IN-IP/UDP" 
    UDP/4789 is used.

    Also ETH header adds up 14 Bytes. (18 Bytes with VLAN data, but usually it gets added to VXLAN header)
    Since L2 header is not counted up to starting MTU (up to 1500 bytes) of not encapsulated packet.

That means each VXLAN PDU accumulates additional 50 Bytes of MTU to the tunnel.

VXLAN virtual identifier (VNID) allows up to 16 million diffrent values. 
VLAN only allows 4096.

While LISP has ITR and ETR, in VXLAN, routers are called VTEP.

VXLAN is Data Plane protocol only, by itself it cannot move packets in the network since it doesn't know where to move them.
Control Plane protocol is required: 
    - Usually MP-BGP is used for that
    - ACI uses COOP
    - SDA uses LISP


#                    STP (Spanning-tree protocol) 

  !#####!   BPDUs IN A CONVERGED TOPOLOGY ARE INITIATED BY ROOT BRIDGE BY DEFAULT. IF NON-ROOT BRIDGES DOESN'T RECEIVE BPDU FROM ROOT, THEY WON'T SEND THEIR OWN BPDUs.

https://linkmeup.ru/podcasts/977/
STP (802.1D) - protocol that allows switches to become aware of other switches through advertising and receiving of BPDUs. Also build loop-free topology
BPDU - Bridge Protocol Data Unit. Some of BPDU information that is exchanged between switches within STP process:
    Bridge ID - An ID of each switch which consists of:
        - Bridge Priority (default - 32768, steps are 4096)
        - Base MAC-Address
        - VLAN number (number is added to priority value)
        Root Bridge is usually chosen by manually set priority. If both Priority value and VLAN are same, then tiebreaker is MAC
    Port Cost - Cost of port (depends on port bandwidth)
        - Ethernet (10Mbit/s) has a cost of 100
        - FastEthernet (100Mbit/s) has a cost of 19
        - GigabitEthernet (1,000Mbit/s) has a cost of 4
        There are different standarts to STP specifying the cost of ports (802.1d-1990 - unique values up to 600Mbit/s, 802.1d-1998 - unique values up to 50Gbit/s, 802.1t-2001)
    Root Path Cost - Consist of Port Cost sums for all the links on the way to Root Bridge
    Port Priority + ID - An STP Port Priority (default value is 128). Also adds up the port ID in system. gi0/0 is 1, gi0/4 is 5 and on.

There are 2 types of BPDU:
    Configuration BPDUs - is sent out initially during first negotiation and STP domain establishement
    Notification BPDUs (TCN topology change notification) - is sent out when configuration change (or failure) happens. TCN then is being forwarded up to ROOT, then root sends out the BPDU with confirmed topology change.

Elect Root Bridge ID:
    Each switch at the beginning sends out BPDUs saying "I AM ROOT BRIDGE". 
    Whenever device receives BPDU with lower Priority value, or Base MAC-Address, it stops considering itself Root and proceeds to choose root ports.

Elect Root port:
    Root port is chosen based on the Port cost towards the Root. 
    Root switch advertises cost to Root as value 0 (since it is a Root). Each following switch advertise cost to root as 0 + it's own best value.
    If switch has two ways with same port costs towards Root, the port towards the bridge with lower bridge ID will be chosen as Root.
    If all potential Root ports are leading to switches with the same bridge IDs, Root port will be elected based on lower priority + port ID of the connected Switch.

Elect Designated port:
    Designated port is port facing away from the root (basically any NON-ROOT). 
    In the link between two switches, there is only 1 (ONE) designated port and one blocking port.
    1. Chosen based on the path cost to the ROOT (can be checked with "sh spanning-tree vlan 10 root cost")
    2. If path to ROOT is of the same cost, Designated port is chosen on the switch with lowest bridge ID (priority-vlanID-MAC)
    
Used for network to be redundant AND loop-proof. In a topology with many links going between devices, a root switch is elected through certain means, then the topology is build for every device in broadcast domain to be able to reach the root though SINGLE path.
Root gets all ports used. Downstream switches only have a single path to the root, others can never lead to root switch in normal circumstances.

STP port states:
Disabled - Port is admin down
Blocking - Port cannot forward network traffic. Can receive BPDUs
Listening - Can't forward network traffic. Can receive and forward BPDUs
Learning - Can't forward network traffic. Can receive and send BPDUs and alter MAC address table based on received network traffic 
Forwarding - Port operates as usual
Broken - Port discards packets while issue exists

Interface types: 
    P2P = FULL DUPLEX interface (FDI)
    P2P Edge = FDI with portfast turned on
    P2P Peer(STP) = FDI with neighbor on that interface running older version of STP
    Shr = HALD DUPLEX interface
    Shr Edge, Shr Peer(STP) apply as above for shared ports as well.

Timers in 802.1D:
    Hello Time (def 2 sec) - how often does BPDUs are sent out. When non-root bridge receives BPDU (initially sent out by ROOT only), it sents out it's own BPDU to ports int LRN and FWD state
    Max Age (def 20 sec) - if switch doesn't receive BPDUs from neighboring device for that amount of time, port is transitioned to blocking state and (if it was on a root port) new root port is chosen
    Forward Delay (def 15 sec) - how long does switch stay in LISTENING and LEARNING states after topology change
    Aging Time (def 300 sec) - how long does dynamically learned MAC-address is kept in the MAC-address table if there is no traffic received from it
        Timer is set to 15sec if topology has been changed (TCN sent/received)
        
STP customization:

Uplinkfast - if switch has more than one port in the direction of root, this feature allows it to transition that port from blocking directly to forwarding state if the active root port stops being operation (admin shutdown or anything else)
        To turn feature on: "spanning-tree uplinkfast" in global config mode. Used only to response to failure that is detected on switches own link (from other side as well)
        + 3000 to port cost; 
        + a lot to the bridge priority (+ ~16000)

Backbonefast - if switch gets cut out of it's root port (shutdown or failure on any side) and the only other link towards the root is in blocking state from other end, the switch will think it is a root bridge (since blocking port doesn't send BPDUs) and will send out it's own BPDUs "i am now root bridge". Feature allows to detect these occasions (on the switch which has a blocking port) and response by sending a backbonefast request to current root to make sure it's still there and will then transition it's blocking port to designated state (to send out BPDUs) to let switch with failed link know that there is a better bridge (with better bridge ID)

Portfast - feature that allows to specify ports connected to single devices and bypass the LIS and LRN states when they come up. Port up/down events will not be considered as topology change (hence no TCN)
    Can be configured on port or globally (if globally, ACCESS interfaces are switched to portfast)
    Can be configured on trunk - "spanning-tree portfast edge trunk"

BPDU Filter (usually in combo with Portfast) - a feature that prohibits BPDUs from being sent or received on specified interface.
    Can be configured on port or globally (if globally, feature is applied to interfaces with PORTFAST)
    "spanning-tree bpdufilter enable"

Root Guard - a feature enabled on the interface that prohibits STP topology changes if these interfaces receive BPDUs with bridge IDs better that current root bridge ID
    Enabled on the interface - "spanning-tree guard root"
    
BPDU Guard - a feature that is applied to the interface with PORTFAST configured, puts the interface in err-disabled state if it received BPDUs
    Usually, portfast configured on ports towards the endpoint hence it will not send BPDUs. If by mistake some switch is connected to that port, interface will go down
    Can be configured on port or globally (if globally, feature is applied to interfaces with PORTFAST)
    Enabled on the interface - "spanning-tree bpduguard enable"

Loop Guard - a feature that attempts to prevent any loops that could arise by forcing the blocked ports to transition into BROKEN state instead of LIS and LRN after not receiving BPDUs for the duration of Max Age (20 seconds)
    Can be configured on port or globally
    Enabled on the interface - "spanning-tree guard loop"
    
UDLD (UniDirectional Link Detection) - a feature that allows to watch the physical state of links between switches since STP-wise everything can be fine but issues on the physics may break the link with no clear indication of that


RAPID SPANNING TREE
RSTP (802.1W) - faster, younger, cooler version of STP with some additions comparing to initial protocol.
    RSPT MAIN POINTS:
    Enabled globally "spanning-tree mode rapid-pvst" (on Cisco)
    Uplinkfast and Backbonefast are automatically included into the RSTP (no need to configure)
    If case of Topology Change (TCN), switch that detected the change sends out the topology change BPDU instead of forwarding it to ROOT first
    Usually Max Age timer (when no BPDUs received for that time, link is considered as failed) is 20 seconds but in RSTP the issue is detected if no BPDUs are received for 6 seconds

    !#####!  IN RSTP, BPDUs ARE SENT OUT EVERY *hello_timer* SECONDS AUTOMATICALLY. ROOT BRIDGE DOESN'T HAVE TO TRIGGER EVERYONE BY SENDING BPDU FIRST.

What remained the same in 802.1w:
    Root ports
    Designated ports

What changed:
    Blocked ports now divided into two different roles
        Alternate port (port is blocked but could be ROOT PORT) - it is allowed to transition to forwarding if root port fails. Basically it received 2nd best BPDU
        Backup port (port is blocked but could be DESIGNATED port) - it serves as backup to DESIGNATED port. Not seen often nowadays because it required few ports on one switch to be connected to shared medium (like hub)

RSTP Port states:
    (BLK)Discarding (combines Disabled, Blocking and Listening states from original STP) - receives BPDUs on the interface. Doesn't forward user data. Doesn't add MAC-addresses to MAC table
    (LRN)Learning - receives and sends out BPDUs. Adds MAC-address to MAC table for user data traffic but doesn't forward the data
    (FWD)Forwarding - Receives&sends out BPDUs, forwards user traffic


#                    MST (Multiple Spanning Tree) (802.1S)

MST allows creation of STP instances and to include VLANs to that instances. That is next level to PVST since PVST creates a new STP instance for each VLAN. If there are many VLANs - huge resource load will be created.

It can be used for load balancing - Create 2 instances for 2 different paths and use both to forward traffic for half VLANs through one path and other half through another.

    MST configuration:
    In MST, there is a concept of "REGION".
    Region - a nubmer of switches running in the same MST-"domain".
    
    For switches to belong to same Region, following should match for them:
        Region Name;
        Revision Number;
        Instances with VLAN mappings (VLANs are mapped to instances).
        
    There is always Internal Spanning-Tree (IST) Instance - 0. Apart from 0, any number up to 16 can be used.
    When configuring MST, first of all "spanning-tree mode mst" should be run to change STP mode to MST.
    
MST uses long port cost by default:

BW------short---long--|
10mb-----100---2000000|
100mb----19----200000-|
1000mb---4-----20000--|
10000mb--2-----2000---|

MST switches exchange BPDUs just for region instance 0 which is IST (Internal Spanning-tree). 
Within these BPDUs, there is an information about all other MST instances. 
In that BPDUs, there is an information about Instance 0, it's root bridge ID, root cost, protocol identifier (MST).
Also there's MST instances data, it's root bridge ID.

!When there's a switch in topology that doesn't belong to the MST region.
   -If there's a switch that is not in MST region, all the MST switches connected to it will advertise (in BPDUs) the ROOT bridge of IST. And the cost for EACH switch to reach the root will be 0.
    The tiebreaker for which port to be ROOT and which one to be blocking is about the bridge ID of a switch connected to each port.
    Each advertisement has a root cost of 0, root bridge is is the same (ROOT of IST), but advertising switch bridge ID will differ, based on that the decision will be made.
    That sometimes can lead to suboptimal path but it is what it is.
   -If the switch not is MST region is recognized to be Cisco running PVST, all the MST switches will send out a BPDU for each VLAN that should be advertised over trunk between them.



#                    Trunking protocols (802.1Q, VTP, DTP)

802.1Q - the true trunking protocol. Allows to exchange tagged packets between switches (of ANY vendors)
VTP (VLAN trunking protocol) - Allows switches to exchange VLAN DB data between each other. If VLAN is created on some switch, other switch connected to it creates same VLAN automatically
DTP (Dynamic Trunking Protocol) - Allows switches to form TRUNK links automatically if two switches are connected between each other and configured accordingly:
    "Auto" mode - "i'll be trunk if you want to". Only receives packets. Trunk will be formed only if other side is "Desirable" mode or Hardcoded TRUNK (switchport mode trunk). 
    "Desirable" mode - "i want to be a trunk, do you want to?". Switch sends out packets to form a trunk between switches. Trunk will be formes if other device is configured with "desirable" mode or "auto" mode or hardcoded trunk.
    Hardcoded trunk is a one, that is configured by entering "Switchport mode trunk"
    
    DTP is not recommended due to "VLAN HOPPING ATTACK". Trunk should be hardcoded manually.
    

#                    EtherChannels (troubleshoot,configure) - basic, LACP, PAgP(ciscoProprietary)
Usual Etherchannel - just turn on the port-channel on both sides
    When in usual mode, "show etherchannel" won't show that EC is down.
LACP (Link Aggregation Control Protocol) - two modes of EC (passive - enable LACP only if LACP device is detected) (active - enable LACP unconditionally)
PAgP (Port Aggregation Protocol) - two modes of EC (auto - enable PAgP only if PAgP device is detected) (desirable - Enable PAgP unconditionally)

TSHOOT:
    "show interfaces port-channel" - check port-channel interface (members, speed)
    "show lacp/pagp counters" - check counters, DUs that are exchanged
    "show lacp/pagp internal" - check EC mode, rate of DUs
    "show lacp/pagp neighbor" - check EC mode, rate of DUs FOR THE NEIGHBOR

Advanced LACP features:
    "lacp rate fast" - Enable Fast LACPDUs (Slow ones are transmitted once in 30 seconds, fast ones are once every second). Have to be configured on both sides
    "port-channel min-links" - Set a minimum links at which the port-channel will be a port-channel. If there are 4, minimum is 4 and one link fails - port-channel is destroyed to usual links
    "port-channel max-bundle" - Set a maximum links available in PC. If there are 2 IFs in PC, you configure maximum to 1, then one interface will got to "Hot-Standby" mode.
    "show lacp sys-id / lacp system-priority" - Check / Specify LACP priority for the switch. Used if MIN or MAX links are configured. Switch LACP priority allows for device to specify which interface is chosen as an active and which one as HOT-STANDBY.
    "lacp port priority" - Specify PORT priority opposed to whole Switch priority. Also used to manually specify which interface should be turned to Hot-standby
    CHOICE GOES TO THE LEAST PRIORITY!
    
    

#                    Routing 

Dynamic routing protocols:
    IGP (Interior Gateway Protocol)
        RIP;
        EIGRP;
        OSPF;
        IS-IS;
    EGP (Exterior Gateway Protocol)
        BGP.

Autonomous System - a set of routers and networks under same management
    IGP is best suited to share routes within same AS.
        - better speed
        - better responsiveness
    EGP is better suited to share routes between AS'es
        - better stability
        - better security

Link State Routing protocols (OSPF, IS-IS)
    (*)Router know the whole topology
    Takes more RAM / CPU
    Faster convergence     
Distance Vector Routing protocols (RIP, EIGRP)
    (*)Router know only about the next hop
    Takes less RAM / CPU
    Slower convergence
    (((())))EIGRP is an ADVANCED Distance Vector


